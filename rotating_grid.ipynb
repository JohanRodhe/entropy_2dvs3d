{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate entropy differences 2D/3D\n",
    "## The notebook is divided into different parts. The first contains functions to divide into a grid, project and calculate the entropy. In the end are functions to plot the results i.e. heatmaps and boxplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install orthoproj\n",
    "#!pip install joblib\n",
    "#!pip install --upgrade pip\n",
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.datasets import make_blobs\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numba\n",
    "#from numba import jit\n",
    "#from numba import njit, prange\n",
    "from scipy.spatial import ConvexHull, convex_hull_plot_2d\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "from orthoproj import OrthoProj\n",
    "from itertools import combinations\n",
    "from itertools import combinations_with_replacement\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data needs to be structured in a specific way for the reading to work. If your data is structured in another way then change here.\n",
    "### CellID&nbsp;&nbsp;&nbsp;&nbsp;X&nbsp;&nbsp;&nbsp;&nbsp;Y&nbsp;&nbsp;&nbsp;&nbsp;Z&nbsp;&nbsp;&nbsp;&nbsp;Cluster(int)&nbsp;&nbsp;&nbsp;&nbsp;CellType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read 3D data from path. Requires label names column name to be \"Type\" and label int to be TypeInt.\n",
    "def read3d(path):\n",
    "    df = pd.read_csv(path, sep=\"\\t\")#.sample(n=10000, random_state=1)\n",
    "    #label_names = df['Type']\n",
    "    labels = df[\"TypeInt\"].values\n",
    "    X = df[[df.columns[0], df.columns[1], df.columns[2]]].values\n",
    "    return X, labels\n",
    "\n",
    "# Read 2D data from path. Requires label names column name to be \"Type\" and label int to be TypeInt. \n",
    "def read2d(path):\n",
    "    df = pd.read_csv(path, sep=\"\\t\")#.sample(n=10000, random_state=1)\n",
    "    label_names = df['Type']\n",
    "    labels = df[\"TypeInt\"].values\n",
    "    if (\"Cluster\" in df):\n",
    "        clusters = df[\"Cluster\"].values\n",
    "    else:\n",
    "        clusters = None\n",
    "    X = df[[df.columns[0], df.columns[1]]].values\n",
    "    return X, labels, label_names, clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart2sph(x, y, z):\n",
    "    hxy = np.hypot(x, y)\n",
    "    r = np.hypot(hxy, z)\n",
    "    el = np.arctan2(z, hxy)\n",
    "    az = np.arctan2(y, x)\n",
    "    return az, el, r\n",
    "\n",
    "def sph2cart(az, el, r):\n",
    "    rcos_theta = r * np.cos(el)\n",
    "    x = rcos_theta * np.cos(az)\n",
    "    y = rcos_theta * np.sin(az)\n",
    "    z = r * np.sin(el)\n",
    "    return x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate entropy in each grid-cell.\n",
    "def calc_global_entropy(data, x_edges, y_edges, anno):\n",
    "    total_entropy = 0\n",
    "    for i in range(len(x_edges)-1):\n",
    "        id_x = (data[:, 0] >= x_edges[i]) & (data[:, 0] < x_edges[i+1])\n",
    "        if id_x.sum() == 0:\n",
    "            continue\n",
    "        for j in range(len(y_edges)-1):\n",
    "            id_y = (data[:, 1] >= y_edges[j]) & (data[:, 1] < y_edges[j+1])\n",
    "            if id_y.sum() == 0:\n",
    "                continue\n",
    "            a = anno[id_x & id_y]\n",
    "            if len(a) < 2:\n",
    "                continue\n",
    "            uc = np.bincount(a)\n",
    "            ii = np.nonzero(uc)[0]\n",
    "            v = np.array(list(zip(ii,uc[ii])))[:, 1]\n",
    "            p = v/ v.sum()\n",
    "            si = -(p*np.log(p)).sum()\n",
    "            total_entropy += si\n",
    "    return total_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the grid. The expand is used to ensure the grid covers all points even when it is moved around\n",
    "expand = 1.2\n",
    "def make_grid(X, n_grids):\n",
    "    if np.shape(X)[1] == 3:\n",
    "        xx, yy, zz = (np.linspace(X[:,0].min()*expand, X[:,0].max()*expand, n_grids),\n",
    "                        np.linspace(X[:,1].min()*expand, X[:,1].max()*expand, n_grids),\n",
    "                        np.linspace(X[:,2].min()*expand, X[:,2].max()*expand, n_grids))\n",
    "        return xx,yy,zz\n",
    "    else:\n",
    "        xx, yy = (np.linspace(X[:,0].min()*expand, X[:,0].max()*expand, n_grids),\n",
    "             np.linspace(X[:,1].min()*expand, X[:,1].max()*expand, n_grids))\n",
    "        return xx,yy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the grid around and calculate the entropy for each placement. Save the lowest value i.e. where the grid placement was the best.\n",
    "def calc_total_ge(X, steps, xx, yy, subset, groups):\n",
    "    dx = (abs(xx[-1])-abs(xx[-2]))/steps\n",
    "    dy = (abs(yy[-1])-abs(yy[-2]))/steps\n",
    "    #print (dx, dy, dz)\n",
    "    res = [] \n",
    "    for i in range(steps):\n",
    "        for j in range(steps):\n",
    "            ge = calc_global_entropy(X, xx+dx*i, yy+dy*j, groups[subset])\n",
    "            res.append((ge, i, j))\n",
    "    res = pd.DataFrame(res, columns=['entropy', 'x_offset', 'y_offset'])\n",
    "    return res, dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projects the 3D data onto two dimensions. The projection is determined by azimuth angle and elevation angle. The loop will go step through angles determined by az_step and el_step. Returns all projections in a dataframe.\n",
    "def get_projections(az_step, el_step):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    ax.scatter(X3d[:,0], X3d[:,1], X3d[:,2], s=10, c=labels)\n",
    "    projections = []\n",
    "    for az_angle in range(0, 180+az_step, az_step):\n",
    "        for elev_angle in range(0, 180+el_step, el_step):\n",
    "            ax.view_init(elev=elev_angle, azim=az_angle) \n",
    "            x2, y2, _ = proj3d.proj_transform(X3d[:,0], X3d[:,1], X3d[:,2], ax.get_proj())\n",
    "            projections.append([x2, y2, az_angle, elev_angle])\n",
    "    projections_df = pd.DataFrame(projections, columns=['x', 'y', 'azimuth_angle', 'elevation_angle'])\n",
    "    return projections_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the minimum global entropy for all projections for a combination of clusters. Return the minimum entropy found through all projections.\n",
    "def calc_min_ge(projections, comb, groups):\n",
    "    nr_proj = projections.shape[0]\n",
    "    proj_res = []\n",
    "    subset = np.where((groups == comb[0]) | (groups == comb[1]))\n",
    "    for i in range(nr_proj):\n",
    "        X = np.array([projections['x'][i], projections['y'][i]]).T\n",
    "        X_subset = X[subset]*1000\n",
    "        xx3d, yy3d = make_grid(X_subset, 10)\n",
    "        result3d, dx3d, dy3d = calc_total_ge(X_subset, 10, xx3d, yy3d, subset, groups)\n",
    "        min_ge3d = result3d.sort_values('entropy').iloc[0]\n",
    "        proj_res.append([min_ge3d[0], min_ge3d[1], min_ge3d[2], comb[0], comb[1], projections['azimuth_angle'][i], projections['elevation_angle'][i]])\n",
    "    proj_res = pd.DataFrame(proj_res, columns=['min_entropy', 'x_offset', 'y_offset', 'cluster1', 'cluster2', 'azimuth_angle', 'elevation_angle'])\n",
    "    min_ge3d = proj_res.sort_values('min_entropy').iloc[0]\n",
    "    return min_ge3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2d_entropies(X, groups):\n",
    "    results2d = []\n",
    "    for i in tqdm(range(len(combslist))):\n",
    "        comb = combslist[i]\n",
    "        subset = np.where((groups == comb[0]) | (groups == comb[1]))\n",
    "        X_subset = X[subset]\n",
    "        xx2d, yy2d = make_grid(X_subset, 10)\n",
    "        result2d, dx2d, dy2d = calc_total_ge(X_subset, 10, xx2d, yy2d, subset, groups)\n",
    "        min_ge2d = result2d.sort_values('entropy').iloc[0]\n",
    "        results2d.append([min_ge2d[0], min_ge2d[1], min_ge2d[2], comb[0], comb[1]])\n",
    "\n",
    "        #fig = plt.figure()\n",
    "        #ax = fig.add_subplot(111)\n",
    "        #for j in xx2d+dx2d*min_ge2d['x_offset']:\n",
    "        #    ax.axvline(j, c='k', lw=0.2)\n",
    "        #for j in yy2d+dy2d*min_ge2d['y_offset']:\n",
    "        #    ax.axhline(j, c='k', lw=0.2)\n",
    "        #ax.scatter(X_subset[:,0], X_subset[:,1], s=10, c=labels[subset])\n",
    "        #plt.xlim(left, right) \n",
    "        #plt.ylim(up, down)\n",
    "        #plt.title(i)\n",
    "        #previ = currenti\n",
    "        #plt.show()\n",
    "\n",
    "    results2d = pd.DataFrame(results2d, columns=['min_entropy', 'x_offset', 'y_offset', 'cluster1', 'cluster2'])\n",
    "    return results2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib qt\n",
    "def plot_heatmap(path2d, path3d, difference, labels=None):\n",
    "    results3d = pd.read_csv(path3d, sep=\"\\t\")\n",
    "    results2d = pd.read_csv(path2d, sep=\"\\t\")\n",
    "    results3d['cluster1'] = pd.to_numeric(results3d['cluster1'], downcast='integer')\n",
    "    results3d['cluster2'] = pd.to_numeric(results3d['cluster2'], downcast='integer')\n",
    "    # Fill diagonal to make symmetric heatmap.\n",
    "    #for i in range(0,len(labels)):\n",
    "    #    new_row = pd.DataFrame({\"Unnamed: 0\":[0], \"min_entropy\":[0] , \"x_offset\":[0], \"y_offset\":[0], \"cluster1\":[i], \"cluster2\":[i], \"azimuth_angle\":[0], \"elevation_angle\": [0]}) \n",
    "    #    results2d = results2d.append(new_row, ignore_index = True)\n",
    "    #    results3d = results3d.append(new_row, ignore_index = True)\n",
    "    piv = results2d.pivot(\"cluster1\", \"cluster2\", \"min_entropy\")\n",
    "    piv3d = results3d.pivot(\"cluster1\", \"cluster2\", \"min_entropy\")\n",
    "    \n",
    "    fig = plt.figure(figsize= (20,15))\n",
    "    ax = fig.add_subplot(111)\n",
    "    np.fill_diagonal(piv3d.values, np.nan)\n",
    "    np.fill_diagonal(piv.values, np.nan)\n",
    "    if (difference == True):\n",
    "        diff = piv - piv3d\n",
    "        mine = np.nanmin(np.array(diff))\n",
    "        maxe = np.nanmax(np.array(diff))\n",
    "        extreme_value = max(abs(maxe), abs(mine))\n",
    "        cmap = plt.cm.bwr\n",
    "        ax = sns.heatmap(diff, xticklabels=d.values(), vmin=-extreme_value, vmax=extreme_value, yticklabels=d.values(), square=True, cmap=cmap)#, cmap=cmap)\n",
    "        ax = sns.heatmap(diff.T, xticklabels=d.values(), vmin=-extreme_value, vmax=extreme_value, yticklabels=d.values(), square=True, cmap=cmap, cbar=False)#, cmap=cmap)\n",
    "        ax.invert_yaxis()\n",
    "        ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "    else:    \n",
    "\n",
    "\n",
    "        mine = results2d['min_entropy'].min()\n",
    "        maxe = results2d['min_entropy'].max()\n",
    "\n",
    "        #tot_results = piv.append(pivt)\n",
    "        cmap = plt.cm.hot\n",
    "        cmap.set_under(color=\"black\")\n",
    "        ax = sns.heatmap(piv, vmin=mine, vmax=maxe, xticklabels=d.values(), yticklabels=d.values(), square=True)#, cmap=plt.cm.seismic)\n",
    "        ax = sns.heatmap(piv3d.T, vmin=mine, vmax=maxe, xticklabels=d.values(), yticklabels=d.values(), square=True, cbar=False)#, cmap=plt.cm.seismic)\n",
    "        ax.invert_yaxis()\n",
    "        ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "    #ax.set_xlim(0, 40)\n",
    "    #figpath = path2d + \"_\" + path3d + \".png\"\n",
    "    #plt.savefig(path3d + \"_heatmap.png\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_violin(path2d, path3d):\n",
    "    results3d = pd.read_csv(path3d, sep=\"\\t\")\n",
    "    results2d = pd.read_csv(path2d, sep=\"\\t\")\n",
    "    results3d['cluster1'] = pd.to_numeric(results3d['cluster1'], downcast='integer')\n",
    "    results3d['cluster2'] = pd.to_numeric(results3d['cluster2'], downcast='integer')\n",
    "    # Fill diagonal to make symmetric heatmap.\n",
    "    #for i in range(0,len(labels)):\n",
    "    #    new_row = pd.DataFrame({\"Unnamed: 0\":[0], \"min_entropy\":[np.nan] , \"x_offset\":[0], \"y_offset\":[0], \"cluster1\":[i], \"cluster2\":[i], \"azimuth_angle\":[0], \"elevation_angle\": [0]}) \n",
    "    #    results2d = results2d.append(new_row, ignore_index = True)\n",
    "    #    results3d = results3d.append(new_row, ignore_index = True)\n",
    "    piv = results2d.pivot(\"cluster1\", \"cluster2\", \"min_entropy\")\n",
    "    np.fill_diagonal(piv.values, np.nan)\n",
    "    pivt = results3d.pivot(\"cluster1\", \"cluster2\", \"min_entropy\").T\n",
    "    np.fill_diagonal(pivt.values, np.nan)\n",
    "    \n",
    "    results3d['Dim'] = '3D'\n",
    "    results2d['Dim'] = '2D'\n",
    "    \n",
    "    results2d_nonzero = results2d[results2d['min_entropy'] > 0]\n",
    "    results3d_nonzero = results3d[results3d['min_entropy'] > 0]\n",
    "    df = results2d.append(results3d, ignore_index=True)\n",
    "    df[\"N\"] = \"All\"\n",
    "    df_nonzero = results2d_nonzero.append(results3d_nonzero, ignore_index=True)\n",
    "    df_nonzero[\"N\"] = \"Non-zero\"\n",
    "    df_all = df.append(df_nonzero, ignore_index=True)\n",
    "    #print(results2d)\n",
    "    #df = results2d.append(results3d)\n",
    "    fig = plt.figure(figsize=(16,10))\n",
    "    ax = fig.add_subplot(131)\n",
    "    ax = sns.boxplot(x=\"N\", y=\"min_entropy\", hue=\"Dim\", data=df_nonzero, palette=\"muted\")\n",
    "    #ax = sns.violinplot(x=\"N\", y=\"min_entropy\", hue=\"dim\", data=df_all, palette=\"muted\", split=True, scale=\"count\", bw=0.2, inner=\"quartile\")\n",
    "    #plt.savefig(path3d + \"_violin.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_boxplots(paths2d, paths3d):\n",
    "    cols = 6\n",
    "    rows = len(paths2d) / cols\n",
    "    fig = plt.figure(figsize=(30,20))\n",
    "    for n in range(len(paths2d)):\n",
    "            results3d = pd.read_csv(paths3d[n], sep=\"\\t\")\n",
    "            results2d = pd.read_csv(paths2d[n], sep=\"\\t\")\n",
    "            results3d['cluster1'] = pd.to_numeric(results3d['cluster1'], downcast='integer')\n",
    "            results3d['cluster2'] = pd.to_numeric(results3d['cluster2'], downcast='integer')\n",
    "            \n",
    "            piv = results2d.pivot(\"cluster1\", \"cluster2\", \"min_entropy\")\n",
    "            np.fill_diagonal(piv.values, np.nan)\n",
    "            piv3d = results3d.pivot(\"cluster1\", \"cluster2\", \"min_entropy\")\n",
    "            np.fill_diagonal(piv3d.values, np.nan)\n",
    "            results3d['Dim'] = '3D'\n",
    "            results2d['Dim'] = '2D'\n",
    "            results2d_nonzero = results2d[results2d['min_entropy'] > 0]\n",
    "            results3d_nonzero = results3d[results3d['min_entropy'] > 0]\n",
    "            df_nonzero = results2d_nonzero.append(results3d_nonzero, ignore_index=True, sort=False)\n",
    "            df_nonzero[\"N\"] = \"Non-zero\"\n",
    "            diff = piv - piv3d\n",
    "            zeroes = np.count_nonzero(np.array(diff == 0).flatten())\n",
    "            lt = np.count_nonzero(np.array(diff < 0).flatten())\n",
    "            gt = np.count_nonzero(np.array(diff > 0).flatten())\n",
    "\n",
    "            ax = fig.add_subplot(rows,cols,n+1)\n",
    "            ax = sns.boxplot(x=\"N\", y=\"min_entropy\", hue=\"Dim\", data=df_nonzero, palette=\"muted\")\n",
    "\n",
    "            params = {\"legend.fontsize\": 32, \"legend.handleheight\": 1, \"legend.handlelength\": 2.5, \"legend.title_fontsize\": 38}\n",
    "            plt.rcParams.update(params)\n",
    "            ax.legend_.remove()\n",
    "            ax.set_xlabel(\"\")\n",
    "            #t = ax.annotate(\" No diff: \" + str(120) + \"\\n 2D better : \" + str(130) + \"\\n 3D better: \" + str(140),\n",
    "            #            xy=(0.75, 0.8),\n",
    "            #            xycoords=\"axes fraction\",\n",
    "            #            bbox=dict(facecolor=\"blue\", fc=(1.0, 0.7, 0.7), ec=\"none\"))\n",
    "            #t.set_bbox(dict(facecolor='white', alpha=0.8))\n",
    "            words = paths3d[n].split(\"\\\\\")[1].split(\"_\")\n",
    "            #print(str(zeroes + lt + gt) + \" \" + words[0] + \" \" + words[1] + \" \" + words[2])\n",
    "            if (words[0] == \"mca\"):\n",
    "                words[0] = words[0].upper()\n",
    "            else:\n",
    "                words[0] = words[0].capitalize()\n",
    "            if (words[1] == \"tsne\"):\n",
    "                words[1] = \"tSNE\"\n",
    "            else:\n",
    "                words[1] = words[1].upper()\n",
    "            if (words[2] == \"celltypes\"):\n",
    "                words[2] = \"Cell Types\"\n",
    "            else:\n",
    "                words[2] = \"Louvain\"\n",
    "            ax.set_title(words[0] + \" \" + words[1] + \" \" + words[2] + \"\\n  No Difference: \" + str(zeroes) + \"\\n 2D Superior : \" + str(lt) + \"\\n 3D Superior: \" + str(gt), fontsize=14, fontweight=\"bold\")\n",
    "            \n",
    "            #ax.set_title(\"Entropy Method\", fontsize=38, fontweight=\"bold\")\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting original 2d points results.\n",
    "def plot_clusters(ind, groups, path2d, path3d, label_names):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    #ax = fig.add_subplot(131)\n",
    "    #scatter = ax.scatter(X2d[:,0], X2d[:,1], s=1, c=labels, cmap=ListedColormap(gastru_cmap))\n",
    "    results2d = pd.read_csv(path2d, sep=\"\\t\")\n",
    "    results3d = pd.read_csv(path3d, sep=\"\\t\")\n",
    "    sorted_results2d = results2d.sort_values(\"min_entropy\")\n",
    "    max_entro = sorted_results2d.iloc[ind]\n",
    "    x_offset = max_entro[\"x_offset\"]\n",
    "    y_offset = max_entro[\"y_offset\"]\n",
    "    cl1 = max_entro['cluster1']\n",
    "    cl2 = max_entro['cluster2']\n",
    "    \n",
    "    ## Find clusters where difference between 3d and 2d is largest entropy wise\n",
    "    diff = np.absolute(results2d['min_entropy'] - results3d['min_entropy'])\n",
    "    sorted_diff = pd.DataFrame(diff.sort_values())\n",
    "    cluster_index = sorted_diff.iloc[ind].name\n",
    "    cl1 = results2d.iloc[cluster_index][\"cluster1\"]\n",
    "    cl2 = results2d.iloc[cluster_index][\"cluster2\"]\n",
    "    print(cl1)\n",
    "    print(cl2)\n",
    "    \n",
    "    subset = np.where((groups == cl1) | (groups == cl2))\n",
    "    \n",
    "    X_subset = X2d[subset]\n",
    "    xx2d, yy2d = make_grid(X_subset, 10)\n",
    "    result2d, dx2d, dy2d = calc_total_ge(X_subset, 10, xx2d, yy2d, subset, groups)\n",
    "    min_ge2d = result2d.sort_values('entropy').iloc[0]\n",
    "    print(\"2D entropy: \" + str(min_ge2d['entropy']))\n",
    "    #fig = plt.figure(figsize=(30,10))\n",
    "    ax2 = fig.add_subplot(111)\n",
    "    for j in xx2d+dx2d*x_offset:\n",
    "        ax2.axvline(j, c='k', lw=0.2)\n",
    "    for j in yy2d+dy2d*y_offset:\n",
    "        ax2.axhline(j, c='k', lw=0.2)\n",
    "    scatter = ax2.scatter(X_subset[:,0], X_subset[:,1], s=5, c=groups[subset], cmap=ListedColormap(gastru_cmap_exe_mixed))\n",
    "    legend = ax2.legend(*scatter.legend_elements(), bbox_to_anchor=(0., 1.02, 1., .102), loc='upper left', borderaxespad=0., title=\"Clusters/Cell types\", fancybox=True, framealpha=1, shadow=True, borderpad=1)\n",
    "    legend.get_texts()[0].set_text(label_names[cl1])\n",
    "    legend.get_texts()[1].set_text(label_names[cl2])\n",
    "    ax2.set_xlabel(\"UMAP1\")\n",
    "    ax2.set_ylabel(\"UMAP2\")\n",
    "    ax2.set_title(\"Entropy: \" + str(np.round(min_ge2d['entropy'],2)))\n",
    "    \n",
    "    \n",
    "    #row = results3d.loc[(results3d[\"cluster1\"] == cl1) & (results3d[\"cluster2\"] == cl2)]\n",
    "    #azim_angle = row[\"azimuth_angle\"].values[0]\n",
    "    #elev_angle = row[\"elevation_angle\"].values[0]# and results3d[\"cluster2\"] == cl2]\n",
    "    #X_subset = X3d[subset]\n",
    "    #print(\"3D entropy: \" + str(row[\"min_entropy\"].values[0]))\n",
    "    #ax3 = fig.add_subplot(122, projection='3d')\n",
    "    #scatter2 = ax3.scatter(X_subset[:,0], X_subset[:,1], X_subset[:,2], s=5, c=groups[subset], cmap=ListedColormap(gastru_cmap_exe_mixed))\n",
    "    #ax3.view_init(azim=azim_angle, elev=elev_angle)\n",
    "    #legend2 = ax3.legend(*scatter2.legend_elements(), bbox_to_anchor=(0., 1.02, 1., .102), loc='upper left', borderaxespad=0., title=\"Clusters/Cell types\", fancybox=True, framealpha=1, shadow=True, borderpad=1)\n",
    "    #legend2.get_texts()[0].set_text(label_names[cl1])\n",
    "    #legend2.get_texts()[1].set_text(label_names[cl2])\n",
    "    #ax3.set_xlabel(\"UMAP1\")\n",
    "    #ax3.set_ylabel(\"UMAP2\")\n",
    "    #ax3.set_zlabel(\"UMAP3\")\n",
    "    #ax3.set_title(\"Entropy: \" + str(np.round(row[\"min_entropy\"].values[0],2)))\n",
    "    #plt.savefig(\"exampleclusters_fig.png\", bbox_inches='tight')\n",
    "    #plt.title(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_differences(path2d, path3d, group, fill_diagonal, index_offset=0): \n",
    "    results2d = pd.read_csv(path2d, sep=\"\\t\")\n",
    "    results3d = pd.read_csv(path3d, sep=\"\\t\")\n",
    "    results3d['cluster1'] = pd.to_numeric(results3d['cluster1'], downcast='integer')\n",
    "    results3d['cluster2'] = pd.to_numeric(results3d['cluster2'], downcast='integer')\n",
    "            \n",
    "    piv = results2d.pivot(\"cluster1\", \"cluster2\", \"min_entropy\")\n",
    "    np.fill_diagonal(piv.values, np.nan)\n",
    "    piv3d = results3d.pivot(\"cluster1\", \"cluster2\", \"min_entropy\")\n",
    "    np.fill_diagonal(piv3d.values, np.nan)\n",
    "\n",
    "\n",
    "    \n",
    "    if (fill_diagonal == True and (piv.shape[0] <= len(group) or piv.shape[1] <= len(group))):\n",
    "        for i in range(index_offset, len(group)+index_offset):\n",
    "            new_row = pd.DataFrame({\"Unnamed: 0\":[0], \"min_entropy\":[np.nan] , \"x_offset\":[0], \"y_offset\":[0], \"cluster1\":[i], \"cluster2\":[i], \"azimuth_angle\":[0], \"elevation_angle\": [0]}) \n",
    "            results2d = results2d.append(new_row, ignore_index = True, sort=False)\n",
    "            results3d = results3d.append(new_row, ignore_index = True, sort=False)\n",
    "        piv = results2d.pivot(\"cluster1\", \"cluster2\", \"min_entropy\")\n",
    "        piv3d = results3d.pivot(\"cluster1\", \"cluster2\", \"min_entropy\")\n",
    "\n",
    "    diff = piv - piv3d\n",
    "\n",
    "\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create gray to red colormap\n",
    "cmap2 = LinearSegmentedColormap.from_list('custom blue', \n",
    "                                             [(0,    '#000000'),\n",
    "                                              (0.499, '#ffffff'),\n",
    "                                              (0.5, '#ffffff'),\n",
    "                                              (0.501, '#ffffff'),\n",
    "                                              (1,    '#ff0000')], N=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read files and calculate entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2d, labels, label_names, clusters = read2d(\"Gastrulation_Input_2D_TSNE.txt\")\n",
    "combs = combinations(np.unique(clusters), 2)\n",
    "combslist = np.array(list(combs))\n",
    "results2d = get_2d_entropies(X2d, clusters)\n",
    "results2d.to_csv(\"gastrulation_tsne_louvain_2d_entropies.csv\", sep=\"\\t\")\n",
    "results2d.sort_values('min_entropy').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2d, labels, label_names, clusters = read2d(\"data/Gastrulation_Input_2D_TSNE.txt\")\n",
    "combs = combinations(np.unique(label_names), 2)\n",
    "len(np.unique(label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3d, _ = read3d(\"Gastrulation_Input_3D_TSNE.txt\")\n",
    "X2d, labels, label_names, clusters = read2d(\"Gastrulation_Input_2D_TSNE.txt\")\n",
    "projections = get_projections(10, 10)\n",
    "combs = combinations(np.unique(clusters), 2)\n",
    "combslist = np.array(list(combs))\n",
    "#combtest = combslist[42:50]\n",
    "results3d = []\n",
    "res = Parallel(n_jobs=-1, verbose=5, max_nbytes=None)(delayed(calc_min_ge)(projections, combslist[k], clusters) for k in range(len(combslist)))\n",
    "results3d = pd.DataFrame(res, columns=['min_entropy', 'x_offset', 'y_offset', 'cluster1', 'cluster2', 'azimuth_angle', 'elevation_angle'])  \n",
    "results3d.to_csv(\"gastrulation_tsne_louvain_3d_entropies.csv\", sep=\"\\t\")\n",
    "results3d.sort_values('min_entropy').tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise results\n",
    "## Plot clusters\n",
    "If you want to visualise specific clusters in 2d in 3d to see the difference use this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib qt\n",
    "#az_angle = results3d['']\n",
    "X3d, _ = read3d(\"Gastrulation_Input_3D.txt\")\n",
    "X2d, labels, label_names, clusters = read2d(\"Gastrulation_Input_2D.txt\")\n",
    "l = np.unique(label_names)\n",
    "d = dict([(x,y) for x,y in enumerate(sorted(set(l)))])\n",
    "resultpath2d = \"results/gastrulation_umap_celltypes_2d_entropies.csv\"\n",
    "resultpath3d = \"results/gastrulation_umap_celltypes_3d_entropies.csv\"\n",
    "\n",
    "#cl1 = 5\n",
    "#cl2 = 8\n",
    "#subset = np.where((labels == cl1) | (labels == cl2))\n",
    "#fig = plt.figure(figsize=(20,10))\n",
    "#ax2 = fig.add_subplot(122, projection='3d')\n",
    "#X_subset = X3d[subset]\n",
    "#scatter2 = ax2.scatter(X_subset[:,0], X_subset[:,1], X_subset[:,2], c=labels[subset], cmap=\"copper\")\n",
    "plot_clusters(-1, labels, resultpath2d, resultpath3d, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib qt\n",
    "X3d, _ = read3d(\"Gastrulation_Input_3D.txt\")\n",
    "X2d, labels, label_names, clusters = read2d(\"Gastrulation_Input_2D.txt\")\n",
    "resultpath2d = \"results/gastrulation_umap_celltypes_2d_entropies.csv\"\n",
    "resultpath3d = \"results/gastrulation_umap_celltypes_3d_entropies.csv\"\n",
    "\n",
    "results2d = pd.read_csv(resultpath2d, sep=\"\\t\")\n",
    "results3d = pd.read_csv(resultpath3d, sep=\"\\t\")\n",
    "cl1 = 16\n",
    "cl2 = 22\n",
    "\n",
    "subset = np.where((labels == cl1) | (labels == cl2))\n",
    "fig = plt.figure(figsize=(12,10))\n",
    "row = results3d.loc[(results3d[\"cluster1\"] == cl1) & (results3d[\"cluster2\"] == cl2)]\n",
    "azim_angle = row[\"azimuth_angle\"].values[0]\n",
    "elev_angle = row[\"elevation_angle\"].values[0]# and results3d[\"cluster2\"] == cl2]\n",
    "X_subset = X3d[subset]\n",
    "ax3 = fig.add_subplot(111, projection='3d')\n",
    "scatter2 = ax3.scatter(X_subset[:,0], X_subset[:,1], X_subset[:,2], s=5, c=labels[subset], cmap=ListedColormap(gastru_cmap_exe_mixed))\n",
    "ax3.view_init(azim=180, elev=170)\n",
    "legend2 = ax3.legend(*scatter2.legend_elements(), bbox_to_anchor=(0.2, 1.0, 0.8, .102), loc='upper left', borderaxespad=0., title=\"Clusters/Cell types\", fancybox=True, framealpha=1, shadow=True, borderpad=1)\n",
    "legend2.get_texts()[0].set_text(d[cl1])\n",
    "legend2.get_texts()[1].set_text(d[cl2])\n",
    "ax3.set_xlabel(\"UMAP1\", labelpad=20)\n",
    "ax3.set_ylabel(\"UMAP2\")\n",
    "ax3.set_zlabel(\"UMAP3\")\n",
    "ax3.set_title(\"Entropy: \" + str(np.round(row[\"min_entropy\"].values[0],2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get differences between tsne/umap 2dvs3d entropies and plot joint heatmaps to visualise the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib qt\n",
    "#cmap2 = sns.diverging_palette(h_neg=248, h_pos=11, s=90, l=45, sep=10, as_cmap=True, center=\"light\")\n",
    "_, _, label_names, clusters = read2d(\"data/Gastrulation_Input_2D_TSNE.txt\")\n",
    "celltypes_list = np.unique(label_names)\n",
    "celltypes_dict = dict([(x,y) for x,y in enumerate(sorted(set(celltypes_list)))])\n",
    "clusters_list = np.unique(clusters)\n",
    "clusters_dict = dict([(x,y) for x,y in enumerate(sorted(set(clusters_list)))])\n",
    "data = \"gastrulation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = get_differences(\"results/\" + data + \"_umap_celltypes_2d_entropies.csv\", \"results/\" + data + \"_umap_celltypes_3d_entropies.csv\", celltypes_dict, fill_diagonal=False, index_offset=0)\n",
    "diff2 = get_differences(\"results/\" + data + \"_tsne_celltypes_2d_entropies.csv\", \"results/\" + data + \"_tsne_celltypes_3d_entropies.csv\", celltypes_dict, fill_diagonal=False, index_offset=0)\n",
    "\n",
    "zeroes_diff = np.count_nonzero(np.array(diff == 0).flatten())\n",
    "lt_diff = np.count_nonzero(np.array(diff < 0).flatten())\n",
    "gt_diff = np.count_nonzero(np.array(diff > 0).flatten())\n",
    "\n",
    "zeroes_diff2 = np.count_nonzero(np.array(diff2 == 0).flatten())\n",
    "lt_diff2 = np.count_nonzero(np.array(diff2 < 0).flatten())\n",
    "gt_diff2 = np.count_nonzero(np.array(diff2 > 0).flatten())\n",
    "\n",
    "fig = plt.figure(figsize= (20,15))\n",
    "ax = fig.add_subplot(121, facecolor=(1,1,1), frameon=True)\n",
    "mine = np.nanmin(np.array(diff))\n",
    "maxe = np.nanmax(np.array(diff))\n",
    "extreme_value = max(abs(maxe), abs(mine))\n",
    "diff_tot = (diff2.fillna(0).T + diff.fillna(0))\n",
    "ax = sns.heatmap(diff_tot, xticklabels=celltypes_dict.values(), yticklabels=celltypes_dict.values(), vmin=-extreme_value, vmax=extreme_value,  square=True, cmap=cmap2, cbar=False)#, cmap=cmap)\n",
    "#ax = sns.heatmap(diff, xticklabels=d_ct.values(), yticklabels=d_ct.values(), vmin=-extreme_value, vmax=extreme_value, square=True, cmap=cmap2, cbar=False)#cbar_kws={\"shrink\": 0.5})#, cmap=cmap)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(\"Cell Type\")\n",
    "ax.set_ylabel(\"Cell Type\")\n",
    "ax.tick_params(axis='both', which='major', labelsize=13)\n",
    "for _, spine in ax.spines.items():\n",
    "    spine.set_color(\"black\")\n",
    "    spine.set_visible(True)\n",
    "    spine.set_linewidth(2)\n",
    "# draw diagonal\n",
    "ax.plot((0,256), (0,256), c=\"black\")\n",
    "plt.title(\"Entropy difference between 3D/2D for annotated cell types in \" + data.capitalize() + \"\\n \"\n",
    "          \"UMAP -  No Difference: \" + str(zeroes_diff) + \", 2D Superior : \" + str(lt_diff) + \", 3D Superior: \" + str(gt_diff) + \"\\n\" +\n",
    "          \"tSNE -  No Difference: \" + str(zeroes_diff2) + \", 2D Superior : \" + str(lt_diff2) + \", 3D Superior: \" + str(gt_diff2), fontsize=18)\n",
    "print()\n",
    "\n",
    "diff3 = get_differences(\"results/\" + data + \"_umap_louvain_2d_entropies.csv\", \"results/\" + data + \"_umap_louvain_3d_entropies.csv\", clusters_dict, fill_diagonal=True, index_offset=0)\n",
    "diff4 = get_differences(\"results/\" + data + \"_tsne_louvain_2d_entropies.csv\", \"results/\" + data + \"_tsne_louvain_3d_entropies.csv\", clusters_dict, fill_diagonal=True, index_offset=0)\n",
    "\n",
    "zeroes_diff = np.count_nonzero(np.array(diff3 == 0).flatten())\n",
    "lt_diff = np.count_nonzero(np.array(diff3 < 0).flatten())\n",
    "gt_diff = np.count_nonzero(np.array(diff3 > 0).flatten())\n",
    "\n",
    "zeroes_diff2 = np.count_nonzero(np.array(diff4 == 0).flatten())\n",
    "lt_diff2 = np.count_nonzero(np.array(diff4 < 0).flatten())\n",
    "gt_diff2 = np.count_nonzero(np.array(diff4 > 0).flatten())\n",
    "\n",
    "\n",
    "#fig = plt.figure(figsize= (30,20))\n",
    "ax = fig.add_subplot(122, facecolor=(1,1,1), frameon=True)\n",
    "mine = np.nanmin(np.array(diff3))\n",
    "maxe = np.nanmax(np.array(diff3))\n",
    "extreme_value2 = max(abs(maxe), abs(mine))\n",
    "diff_tot = (diff4.fillna(0).T + diff3.fillna(0))\n",
    "ax = sns.heatmap(diff_tot, xticklabels=clusters_dict.values(), yticklabels=clusters_dict.values(), vmin=-extreme_value2, vmax=extreme_value2, square=True, cmap=cmap2, cbar=False)# cbar_kws = dict(use_gridspec=False,location=\"left\", shrink=0.5))\n",
    "\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(\"Cluster\")\n",
    "ax.set_ylabel(\"Cluster\")\n",
    "#plt.xticks(rotation=55)\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "for _, spine in ax.spines.items():\n",
    "    spine.set_color(\"black\")\n",
    "    spine.set_visible(True)\n",
    "    spine.set_linewidth(2)\n",
    "# draw diagonal\n",
    "ax.plot((0,256), (0,256), c=\"black\")\n",
    "plt.title(\"Entropy difference between 3D/2D for Louvain clusters in \" + data.capitalize() + \"\\n \"\n",
    "          \"UMAP -  No Difference: \" + str(zeroes_diff) + \", 2D Superior : \" + str(lt_diff) + \", 3D Superior: \" + str(gt_diff) + \"\\n\" +\n",
    "          \"tSNE -  No Difference: \" + str(zeroes_diff2) + \", 2D Superior : \" + str(lt_diff2) + \", 3D Superior: \" + str(gt_diff2), fontsize=18)\n",
    "#plt.savefig(\"results/figures/heatmaps/diff_heatmap_louvain_\" + data + \".png\", bbox_inches='tight')\n",
    "\n",
    "plt.savefig(\"results/figures/heatmaps/diff_heatmap_celltypes_\" + data + \".png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff3 = get_differences(\"results/\" + data + \"_umap_louvain_2d_entropies.csv\", \"results/\" + data + \"_umap_louvain_3d_entropies.csv\", clusters_dict, fill_diagonal=True, index_offset=0)\n",
    "diff4 = get_differences(\"results/\" + data + \"_tsne_louvain_2d_entropies.csv\", \"results/\" + data + \"_tsne_louvain_3d_entropies.csv\", clusters_dict, fill_diagonal=True, index_offset=0)\n",
    "\n",
    "fig = plt.figure(figsize= (30,20))\n",
    "ax = fig.add_subplot(121, facecolor=(1,1,1), frameon=True)\n",
    "mine = np.nanmin(np.array(diff3))\n",
    "maxe = np.nanmax(np.array(diff3))\n",
    "extreme_value2 = max(abs(maxe), abs(mine))\n",
    "diff_tot = (diff4.fillna(0).T + diff3.fillna(0))\n",
    "ax = sns.heatmap(diff_tot, xticklabels=clusters_dict.values(), yticklabels=clusters_dict.values(), vmin=-extreme_value2, vmax=extreme_value2, square=True, cmap=cmap2, cbar=False)# cbar_kws = dict(use_gridspec=False,location=\"left\", shrink=0.5))\n",
    "\n",
    "ax.invert_yaxis()\n",
    "#plt.xticks(rotation=55)\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "for _, spine in ax.spines.items():\n",
    "    spine.set_color(\"black\")\n",
    "    spine.set_visible(True)\n",
    "    spine.set_linewidth(2)\n",
    "# draw diagonal\n",
    "ax.plot((0,256), (0,256), c=\"black\")\n",
    "plt.title(\"Entropy difference between 3D/2D for louvain clusters in \" + data.capitalize(), fontsize=18)\n",
    "plt.savefig(\"results/figures/heatmaps/diff_heatmap_louvain_\" + data + \".png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(diff_tot == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box/Violin plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "results = [f for f in glob.glob(\"results/\" + \"*.csv\")]\n",
    "\n",
    "paths2d = list(filter(lambda x : \"2d\" in x, results))\n",
    "paths3d = list(filter(lambda x : \"3d\" in x, results))\n",
    "\n",
    "fig = plot_multiple_boxplots(paths2d, paths3d)\n",
    "plt.savefig(\"boxplots_entropy_legend.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colormap for Gastrulation figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gastru_cmap = [\"#532C8A\", \"#c19f70\", \"#f9decf\", \"#c9a997\", \"#B51D8D\", \"#3F84AA\", \"#9e6762\", \"#354E23\", \"#F397C0\", \"#ff891c\", \"#635547\", \"#C72228\", \"#f79083\", \"#EF4E22\", \"#7F6874\",\"#989898\",\"#2f694d\", \"#647a4f\",\"#EF5A9D\", \"#FBBE92\",\n",
    "               \"#139992\", \"#cc7818\",\"#f582d1\",\"#8EC792\",\"#C594BF\",\"#C3C388\",\n",
    "                     \"#0F4A9C\",\n",
    "                     \"#FACB12\",\n",
    "                     \"#8DB5CE\",\n",
    "                     \"#1A1A1A\",\n",
    "                     \"#C9EBFB\",\n",
    "                     \"#DABE99\",\n",
    "                     \"#65A83E\",\n",
    "                     \"#CDE088\",\n",
    "                     \"#005579\",\n",
    "                     \"#f7f79e\",\n",
    "                     \"#F6BFCB\"\n",
    "                     \n",
    "              ]\n",
    "gastru_cmap_exe_mixed = [\"#2f694d\", \"#f582d1\"]\n",
    "#gastru_cmap = ListedColormap(gastru_cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gastru_cmap = {\n",
    "    \"Allantois\" : \"#532C8A\",\n",
    "    \"Anterior Primitive Streak\" : \"#c19f70\",\n",
    "     \"Blood progenitors 1\" : \"#f9decf\",\n",
    "     \"Blood progenitors 2\" : \"#c9a997\",\n",
    "     \"Cardiomyocytes\" : \"#B51D8D\",\n",
    "     \"Caudal Mesoderm\" : \"#3F84AA\",\n",
    "    \"Caudal epiblast\" : \"#9e6762\",\n",
    "                     \"Caudal neurectoderm\" : \"#354E23\",\n",
    "                     \"Def. endoderm\" : \"#F397C0\",\n",
    "                     \"Endothelium\" : \"#ff891c\",\n",
    "                    \"Epiblast\" : \"#635547\",\n",
    "                         \"Erythroid1\" : \"#C72228\",\n",
    "                     \"Erythroid2\" : \"#f79083\",\n",
    "                     \"Erythroid3\" : \"#EF4E22\",\n",
    "                     \"ExE ectoderm\" : \"#989898\",\n",
    "                         \"ExE endoderm\" : \"#7F6874\",\n",
    "                     \"ExE mesoderm\" : \"#88D0ad\",\n",
    "                     \"Forebrain/Midbrain/Hindbrain\" : \"#647a4f\",\n",
    "                     \"Gut\" : \"#EF5A9D\",\n",
    "                         \"Haematoendothelial progenitors\" : \"#FBBE92\",\n",
    "    \n",
    "                     \"Intermediate mesoderm\" : \"#139992\",\n",
    "                         \"Mesenchyme\" : \"#cc7818\",\n",
    "    \n",
    "                     \"Mixed mesoderm\" : \"#EFCDE4\",\n",
    "                     \"NMP\" : \"#8EC792\",\n",
    "                     \"Nascent mesoderm\" : \"#C594BF\",\n",
    "    \n",
    "                     \"Neural crest\" : \"#C3C388\",\n",
    "                         \"Notochord\" : \"#0F4A9C\",\n",
    "                     \"PGC\" : \"#FACB12\",\n",
    "                     \"Paraxial mesoderm\" : \"#8DB5CE\",\n",
    "                     \"Parietal endoderm\" : \"#1A1A1A\"\n",
    "    \n",
    "                     \"Pharyngeal mesoderm\" : \"#C9EBFB\",\n",
    "                     \"Primitive Streak\" : \"#DABE99\",\n",
    "                     \n",
    "                     \"Rostral neurectoderm\" : \"#65A83E\",\n",
    "\n",
    "                     \"Spinal cord\" : \"#CDE088\",\n",
    "                     \"Somitic mesoderm\" : \"#005579\",\n",
    "                     \"Surface ectoderm\" : \"#f7f79e\",\n",
    "                     \"Visceral endoderm\" : \"#F6BFCB\",\n",
    "              }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
